#!/usr/bin/env python3

# TODO perhaps this is dumb... I can probably just subscribe to the same thing filescan_logger does :/

from __future__ import annotations

__version__ = '0.1a'

from filescan import logging

logging.basicConfig()
log = logging.getLogger(__name__)

import anyio
import json
import redis.exceptions
import sys
from enum import Enum
from filescan.click import click
from filescan.config import BaseConfig, RedisOptions
from pathlib import Path
from pydantic import BaseModel
from redis.asyncio import Redis


################################################################################
class FilePreservationMode(Enum):
    QUARANTINED = "quarantined"
    ALL = "all"
    NONE = "none"


class ArchivistOptions(BaseModel, frozen=True):
    policy: FilePreservationMode | None = FilePreservationMode.ALL
    redis: RedisOptions = RedisOptions()
    keys: list[str] = ['filescan_notify']


class ArchivistConfig(BaseConfig, frozen=True):
    archivist: ArchivistOptions = ArchivistOptions()


async def watch_pubsub(
    config: ArchivistConfig,
    connection: Redis,
) -> None:
    policy = config.archivist.policy
    keys = config.archivist.keys
    log.info(
        'preservation policy: %s, consuming items from key(s): %s:%d/%d => {%s}',
        policy.value,
        config.archivist.redis.host,
        config.archivist.redis.port,
        config.archivist.redis.db,
        ', '.join(keys),
    )

    try:
        while True:
            result = await connection.brpop(keys, timeout=5)
            if result is None:
                await anyio.sleep(0.5)
                continue

            key, msg = result
            try:
                scan_result = json.loads(msg)
            except json.JSONDecodeError:
                log.warning("Failed to parse JSON from key '%s': %r", key, msg)
                continue

            log.debug("archivist: consumed from key '%s': %r", key, scan_result)

            # TODO: add your actual processing logic here

    except anyio.get_cancelled_exc_class():
        log.info("watch_pubsub cancelled, exiting cleanly")


################################################################################
## MAIN LOGIC ##################################################################
################################################################################


@click.command()
@click.version_option(__version__, help="print the version of this tool and exit")
@click.option("--verbose", "-v", count=True, help="increase logging verbosity (may be repeated)")
@click.option("--quiet/--no-quiet", "-q", help="run silently except for critical errors")
@click.option(
    "--config", "-c", type=click.Path(exists=True, dir_okay=False, path_type=Path), help="specify a config file to load"
)
async def main(
    verbose: int,
    quiet: bool,
    config: Path | None,
) -> None:
    # setup logging properly as early as possible
    logging.basicConfig(verbosity=verbose, quiet=quiet, force=True)

    # get an options object, one way or another
    if config:
        options = ArchivistConfig.from_path(config)
    else:
        log.warning('no config file specified, this is probably not what you ' 'want! continuing anyway...')
        options = ArchivistConfig()

    try:
        try:
            connection = Redis(
                host=options.archivist.redis.host,
                port=options.archivist.redis.port,
                db=options.archivist.redis.db,
                username=options.archivist.redis.username,
                password=options.archivist.redis.password,
                decode_responses=True,
                client_name=Path(sys.argv[0]).stem,
            )
            await connection.ping()

        except redis.exceptions.ConnectionError as exc:
            # log the error, but don't print a novel
            exc.__suppress_context__ = True
            log.debug(
                'failed to open redis connection',
                exc_info=True,
            )
            log.fatal(
                'unable to open redis connection: %s:%d/%d',
                options.archivist.redis.host,
                options.archivist.redis.port,
                options.archivist.redis.db,
            )
            # this is an error we can't really recover from
            sys.exit(1)

        async with (anyio.create_task_group() as group,):
            group.start_soon(watch_pubsub, options, connection)
            await anyio.sleep_forever()

    except anyio.get_cancelled_exc_class():
        pass


if __name__ == "__main__":
    main()
