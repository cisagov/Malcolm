filter {

  if ([id] and [results] and [service][type]) {

    ruby {
      id => "ruby_filescan_remove_empty_values"
      path => "/usr/share/logstash/malcolm-ruby/compact_event.rb"
    }

    if (![event][provider]) {
      mutate {
        id => "filescan_event_provider_fallback"
        add_field => { "[event][provider]" => "filescan" }
      }
    }

    if (![event][dataset]) and ([results][strelka]) {
      mutate {
        id => "filescan_event_dataset_strelka"
        add_field => { "[event][dataset]" => "strelka" }
      }
    }

    # parse the "raw" record passed along as metadata as JSON into @metadata.raw
    if ([metadata][record]) { json {
      id => "filescan_parse_metadata_record"
      source => "[metadata][record]"
      target => "[entity][raw]"
    } } else if ([results][strelka][result][request][attributes][metadata][record]) { json {
      id => "filescan_parse_result_request_metadata_record"
      source => "[results][strelka][result][request][attributes][metadata][record]"
      target => "[entity][raw]"
    } } else if ([results][strelka][result][file][metadata][record]) {
      mutate { id => "mutate_filescan_rename_record_to_raw"
               rename => { "[results][strelka][result][file][metadata][record]" => "[entity][raw][file]" } }
    }

    # store metadata.raw.file._path as dataset, and then move metadata.raw.file to where the
    # originating log normally would be (e.g., service.type:zeek, metadata.raw.file._path:files => zeek.files)
    if ([entity][raw][file][_path]) {
      mutate {
        id => "mutate_filescan_save_raw_log_file_path"
        copy => { "[entity][raw][file][_path]" => "[@metadata][log_file_type]" }
        remove_field => [ "[entity][raw][file][_path]", "[entity][raw][file][_write_ts]" ]
      }
      ruby { id => "ruby_add_file_log_type_to_filescan_dataset"
             code => "event.set('[event][dataset]', [ event.get('[@metadata][log_file_type]'), event.get('[event][dataset]') ].flatten.reject{ |e| e.nil? || e&.empty? })" }
      mutate { id => "mutate_rename_raw_to_original_type"
               rename => { "[entity][raw][file]" => "[%{[service][type]}][%{[@metadata][log_file_type]}]" } }
    }
    # put netbox site in the right place for enrichment later
    if ([entity][raw][netbox][site]) and
       ([entity][raw][netbox][site] != '') {
      mutate {
        id => "mutate_filescan_add_entity_raw_netbox_site"
        copy => { "[entity][raw][netbox][site]" => "[@metadata][nbsiteid]" }
      }
    } else if ([results][strelka][result][file][metadata][record][netbox][site]) and
              ([results][strelka][result][file][metadata][record][netbox][site] != '') {
      mutate {
        id => "mutate_filescan_add_result_record_netbox_site"
        copy => { "[results][strelka][result][file][metadata][record][netbox][site]" => "[@metadata][nbsiteid]" }
      }
    }

    if ([file][size]) {
      ruby {
        id => "ruby_filescan_file_size"
        code => "
          file_size = event.get('[file][size]').to_i
          event.set('[network][bytes]', file_size)
          event.set('[totDataBytes]', file_size)
        "
      }
    }

    # save the filescan's UUID id as into event.id
    mutate {
      id => "mutate_merge_event_id_filescan_id"
      merge => { "[event][id]" => "[id]" }
    }

    # ECS - "file" -> file.type
    mutate { id => "mutate_filescan_add_field_ecs_file_type"
             add_field => { "[file][type]" => "file" } }


    # TODO: merge this stuff with the stuff from the zeek log as it makes sense:

    # generic adds
    # https://www.elastic.co/guide/en/ecs/current/ecs-file.html

    if ([filescan][file][name]) {
      mutate {
        id => "mutate_merge_normalize_filescan_filename"
        merge => { "[file][path]" => "[filescan][file][name]" }
      }
    }

    # if ([filescan][scan][pe]) {
    #     ruby {
    #         code => "
    #             c = event.get('[filescan][scan][pe][sections]')
    #             c.each_with_index do |section, index|
    #                 event.set('[filescan][scan][pe][sections][#{index}][entropy]', section['entropy'].to_f)
    #             end
    #         "
    #     }
    # }
    # mutate {
    #     convert => { "[filescan][scan][pe][sections][entropy]" => "float" }
    # }

    # hashes (will be merged into "related" in 98_finalize.conf)
    # https://www.elastic.co/guide/en/ecs/current/ecs-hash.html
    # https://www.elastic.co/guide/en/ecs/current/ecs-related.html

    if ([filescan][scan][hash][md5]) {
      mutate {
        id => "mutate_merge_field_file_hash_fileinfo_md5"
        merge => { "[file][hash][md5]" => "[filescan][scan][hash][md5]" }
      }
    }

    if ([filescan][scan][hash][sha1]) {
      mutate {
        id => "mutate_merge_field_file_hash_fileinfo_sha1"
        merge => { "[file][hash][sha1]" => "[filescan][scan][hash][sha1]" }
      }
    }

    if ([filescan][scan][hash][sha256]) {
      mutate {
        id => "mutate_merge_field_file_hash_fileinfo_sha256"
        merge => { "[file][hash][sha256]" => "[filescan][scan][hash][sha256]" }
      }
    }

    if ([filescan][scan][hash][ssdeep]) {
      mutate {
        id => "mutate_merge_field_file_hash_fileinfo_ssdeep"
        merge => { "[file][hash][ssdeep]" => "[filescan][scan][hash][ssdeep]" }
      }
    }

    if ([filescan][scan][hash][tlsh]) {
      mutate {
        id => "mutate_merge_field_file_hash_fileinfo_tlsh"
        merge => { "[file][hash][tlsh]" => "[filescan][scan][hash][tlsh]" }
      }
    }

    # File/MIME types ###################################################################################################
    # ECS -> various -> file.mime_type
    # collect all file/MIME types under the parent [file][mime_type] array

    if ([filescan][file][flavors][mime]) {
      mutate {
        id => "mutate_merge_normalize_filescan_fileinfo_mime_type"
        merge => { "[file][mime_type]" => "[filescan][file][flavors][mime]" }
      }
    }
    if ([results][strelka][result][file][mime_type]) {
      mutate {
        id => "mutate_merge_normalize_filescan_result_file_mime_type"
        merge => { "[file][mime_type]" => "[results][strelka][result][file][mime_type]" }
      }
    }
    if ([results][strelka][result][scan][exiftool][mime_type]) {
      mutate {
        id => "mutate_merge_normalize_filescan_result_scan_exiftool_mime_type"
        merge => { "[file][mime_type]" => "[results][strelka][result][scan][exiftool][mime_type]" }
      }
    }

    # if ([filescan][scan][pe]) {
    #   # "mz_file" in [filescan][file][flavors][yara]
    #   # TODO: break file types into separate filters
    # }
    # if ([filescan][scan][elf]) {
    #   # "elf_file" in [filescan][file][flavors][yara]
    # }
    # if ([filescan][scan][macho]) {
    # }

    # if ([filescan][scan][clamav][signature]) {
    #     mutate {
    #       id => "add_clamav_hit_signature"
    #       copy => { "[filescan][scan][clamav][signature]" => "[rule][name]" }
    #       add_field => { "[event][module]" => "ClamAV" }
    #       add_field => { "[rule][category]" => "unknown" }
    #     }
    # }

    # mutate {
    #   remove_field => ["[filescan][scan][pe][resources]"]
    # }

    # from here a lot of this stuff mimics what is done for zeek's files.log, only from the record that came from the filescan metadata

    if [@metadata][log_file_type] {
      # move "up" some fields that are considered to be "multi-log" fields (eg., they # show up in many types of logs)
      mutate {
        id => "mutate_rename_filescan_zeek_common_fields"
        rename => { "[zeek][%{[@metadata][log_file_type]}][ts]"         => "[zeek][ts]" }
        rename => { "[zeek][%{[@metadata][log_file_type]}][uid]"        => "[zeek][uid]" }
        rename => { "[zeek][%{[@metadata][log_file_type]}][fuid]"       => "[zeek][fuid]" }
        rename => { "[zeek][%{[@metadata][log_file_type]}][is_orig]"    => "[network][is_orig]" }
        # this seems redundant but depending on how it came here it might look like any one of these
        rename => { "[zeek][%{[@metadata][log_file_type]}][id][orig_h]" => "[source][ip]" }
        rename => { "[zeek][%{[@metadata][log_file_type]}][id][orig_p]" => "[source][port]" }
        rename => { "[zeek][%{[@metadata][log_file_type]}][id][resp_h]" => "[destination][ip]" }
        rename => { "[zeek][%{[@metadata][log_file_type]}][id][resp_p]" => "[destination][port]" }
        rename => { "[zeek][%{[@metadata][log_file_type]}][id.orig_h]"  => "[source][ip]" }
        rename => { "[zeek][%{[@metadata][log_file_type]}][id.orig_p]"  => "[source][port]" }
        rename => { "[zeek][%{[@metadata][log_file_type]}][id.resp_h]"  => "[destination][ip]" }
        rename => { "[zeek][%{[@metadata][log_file_type]}][id.resp_p]"  => "[destination][port]" }
        rename => { "[zeek][%{[@metadata][log_file_type]}][orig_h]"     => "[source][ip]" }
        rename => { "[zeek][%{[@metadata][log_file_type]}][orig_p]"     => "[source][port]" }
        rename => { "[zeek][%{[@metadata][log_file_type]}][resp_h]"     => "[destination][ip]" }
        rename => { "[zeek][%{[@metadata][log_file_type]}][resp_p]"     => "[destination][port]" }
      }
    }

    # store parent_fuid with fuid
    if ([zeek][files][parent_fuid]) {
      mutate { id => "mutate_filescan_merge_normalize_zeek_files_parent_fuid"
               merge => { "[zeek][fuid]" => "[zeek][files][parent_fuid]" } }
    }

    if ([zeek][uid]) {
      # set zeek connection UID as "rootId" (see logstash.conf output section)
      if (![rootId]) { mutate { id => "mutate_filescan_copy_zeek_rootId"
                                copy => { "[zeek][uid]" => "[rootId]" } } }

      # ECS - zeek.uid -> event.id
      mutate { id => "mutate_filescan_merge_ecs_id_uid"
               merge => { "[event][id]" => "[zeek][uid]" } }
    }

    if ([zeek][fuid]) {
      # ECS - zeek.uid -> event.id
      mutate { id => "mutate_filescan_merge_ecs_id_fuid"
               merge => { "[event][id]" => "[zeek][fuid]" } }
    }

    # ECS -> zeek_files.(md5|sha1|sha256) -> file.hash.(md5|sha1|sha256)
    if ([zeek][files][md5])  { mutate { id => "mutate_filescan_copy_ecs_files_hash_md5"
                                              copy => { "[zeek][files][md5]" => "[file][hash][md5]" } } }
    if ([zeek][files][sha1]) { mutate { id => "mutate_filescan_copy_ecs_files_hash_sha1"
                                              copy => { "[zeek][files][sha1]" => "[file][hash][sha1]" } } }
    if ([file][sha256]) {
      mutate { id => "mutate_rename_filescan_file_sha256"
               rename => { "[file][sha256]" => "[file][hash][sha256]" } }
    } else if ([zeek][files][sha256]) {
      mutate { id => "mutate_filescan_copy_ecs_files_hash_sha256"
               copy => { "[zeek][files][sha256]" => "[file][hash][sha256]" } }
    }

    if ([zeek][files][source]) {
      # do some normalization on files source
      mutate { id => "mutate_gsub_field_filescan_zeek_files_source_spicy_suffix"
               gsub => [ "[zeek][files][source]", "_(TCP|UDP|DATA)$", "" ] }
      mutate { id => "mutate_gsub_field_filescan_zeek_files_source_spicy_prefix"
               gsub => [ "[zeek][files][source]", "^SPICY_", "" ] }

      if ([zeek][files][source] =~ /^XOR decrypted from /) {
        # PE_XOR plugin writes source as "XOR decrypted from FM7Tr545kxt3ofR7x2-"..., let's
        # standardize that to just "XOR decrypted" and put the source fuid in parent_fuid
        grok {
          id => "grok_filescan_zeek_files_source_xor"
          match => { "[zeek][files][source]" => [ "decrypted%{SPACE}from%{SPACE}%{WORD:[@metadata][source_xor_fuid]}" ] }
        }
        if ([@metadata][source_xor_fuid]) { mutate { id => "mutate_merge_filescan_zeek_files_source_xor_parent_fuid"
                                                     merge => { "[zeek][files][parent_fuid]" => "[@metadata][source_xor_fuid]" } } }
        mutate { id => "mutate_replace_filescan_zeek_files_source_xor"
                 replace => { "[zeek][files][source]" => "XOR decrypted" } }

      } else if ([zeek][files][source] == "SSL") {
        # SSL->TLS to match up with what the service field has for cross-referencing
        mutate { id => "mutate_replace_filescan_zeek_files_source_ssl_to_tls"
                 replace => { "[zeek][files][source]" => "TLS" } }
      }

      # ECS -> various -> file.source
      mutate { id => "mutate_filescan_rename_file_source"
               rename => { "[zeek][files][source]" => "[file][source]" } }

      if ([zeek][files][mime_type]) {
        mutate {
          id => "mutate_merge_normalize_filescan_zeek_files_mime_type"
          merge => { "[file][mime_type]" => "[zeek][files][mime_type]" }
        }
      }

      # if we have a network protocol as a "source" field from the original zeek files.log, also store in protocols
      if (![network][protocol]) and
         ([zeek][files][source] !~ /^(<error|PNG|XOR|ZIP)/) {
        mutate { id => "mutate_filescan_merge_zeek_files_source_network_protocol"
                 merge => { "[network][protocol]" => "[zeek][files][source]" } }
        mutate { id => "mutate_filescan_lowercase_zeek_files_source_network_protocol"
                 lowercase => [ "[network][protocol]" ] }
        mutate { id => "mutate_filescan_merge_zeek_files_source_protocol"
                 merge => { "[protocol]" => "[network][protocol]" } }
      }
    }

    if ([file][path]) {
      mutate { id => "mutate_gsub_filescan_path"
               gsub => [ "[file][path]", "^/zeek/extracted-files/", "" ] }
      ruby {
        id => "ruby_filescan_zeek_files_extracted_uri_build"
        code => "
          uri = nil
          if (fName = event.get('[file][path]')) then
            if (tags = event.get('[tags]')) && tags.include?('_filebeat_zeek_hedgehog') then
              if (hName = event.get('[host][name]')) then
                uri = 'hh-extracted-files/' + hName + '/' + fName
              end
            else
              uri = 'extracted-files/' + fName
            end
          end
          event.set('[zeek][files][extracted_uri]', uri) unless uri.to_s.empty?
        "
      }
    }

  } else {
    drop { id => "drop_filescan_invalid_logs" }
  }

}
