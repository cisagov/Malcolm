filter {

  if ([id] and [results] and [service][type]) {

    ruby {
      id => "ruby_filescan_remove_empty_values"
      path => "/usr/share/logstash/malcolm-ruby/compact_event.rb"
    }

    if (![event][provider]) {
      mutate {
        id => "filescan_event_provider_fallback"
        add_field => { "[event][provider]" => "filescan" }
      }
    }

    if (![event][dataset]) and ([results][strelka]) {
      mutate {
        id => "filescan_event_dataset_strelka"
        add_field => { "[event][dataset]" => "strelka" }
      }
    }

    # parse the "raw" record passed along as metadata as JSON into @metadata.raw
    if ([metadata][record]) { json {
      id => "filescan_parse_metadata_record"
      source => "[metadata][record]"
      target => "[entity][raw]"
    } } else if ([results][strelka][result][request][attributes][metadata][record]) { json {
      id => "filescan_parse_result_request_metadata_record"
      source => "[results][strelka][result][request][attributes][metadata][record]"
      target => "[entity][raw]"
    } }

    # store metadata.raw.file._path as dataset, and then move metadata.raw.file to where the
    # originating log normally would be (e.g., service.type:zeek, metadata.raw.file._path:files => zeek.files)
    if ([entity][raw][file][_path]) {
      ruby { id => "ruby_add_file_log_type_to_filescan_dataset"
             code => "event.set('[event][dataset]', [ event.get('[entity][raw][file][_path]'), event.get('[event][dataset]') ].flatten.reject{ |e| e.nil? || e&.empty? })" }
      mutate { id => "mutate_rename_raw_to_original_type"
               rename => { "[entity][raw][file]" => "[%{[service][type]}][%{[entity][raw][file][_path]}]" } }
    }
    # put netbox site in the right place for enrichment later
    if (![@metadata][nbsiteid]) and ([entity][raw][netbox][site]) {
      mutate {
        id => "mutate_rename_filebeat_forwarded_site_id"
        rename => { "[entity][raw][netbox][site]" => "[@metadata][nbsiteid]" }
      }
    }

    # map scan start -> firstPacket, end -> lastPacket
    ruby {
      id => "ruby_filescan_timestamp_calc"
      init => "
        require 'date'
        @parse_to_ms = ->(v) {
          begin
            v && !v.to_s.strip.empty? ?
              (DateTime.parse(v).to_time.to_f * 1000).round :
              nil
          rescue
            nil
          end
        }
      "
      code => "
        ts_val    = event.get('[@timestamp]').to_s
        start_ms = @parse_to_ms.call(event.get('[entity][raw][timestamp]')) || @parse_to_ms.call(event.get('[start]')) || @parse_to_ms.call(ts_val)
        end_ms   = @parse_to_ms.call(event.get('[end]'))   || @parse_to_ms.call(ts_val)
        event.set('[firstPacket]', start_ms)
        event.set('[lastPacket]',  end_ms)
      "
      remove_field => [ "[start]", "[end]" ]
    }

    if ([file][size]) {
      ruby {
        id => "ruby_filescan_file_size"
        code => "
          file_size = event.get('[file][size]').to_i
          event.set('[network][bytes]', file_size)
          event.set('[totDataBytes]', file_size)
        "
      }
    }

    # save the filescan's UUID id as entity.id
    mutate { id => "mutate_rename_filescan_id"
             rename => { "[id]" => "[entity][id]" } }

    # ECS - "file" -> file.type
    mutate { id => "mutate_filescan_add_field_ecs_file_type"
             add_field => { "[file][type]" => "file" } }


    # TODO: merge this stuff with the stuff from the zeek log as it makes sense:

    # generic adds
    # https://www.elastic.co/guide/en/ecs/current/ecs-file.html

    if ([filescan][file][name]) {
      mutate {
        id => "mutate_merge_normalize_filescan_filename"
        merge => { "[file][path]" => "[filescan][file][name]" }
      }
    }

    # if ([filescan][scan][pe]) {
    #     ruby {
    #         code => "
    #             c = event.get('[filescan][scan][pe][sections]')
    #             c.each_with_index do |section, index|
    #                 event.set('[filescan][scan][pe][sections][#{index}][entropy]', section['entropy'].to_f)
    #             end
    #         "
    #     }
    # }
    # mutate {
    #     convert => { "[filescan][scan][pe][sections][entropy]" => "float" }
    # }

    # hashes (will be merged into "related" in 98_finalize.conf)
    # https://www.elastic.co/guide/en/ecs/current/ecs-hash.html
    # https://www.elastic.co/guide/en/ecs/current/ecs-related.html

    if ([filescan][scan][hash][md5]) {
      mutate {
        id => "mutate_merge_field_file_hash_fileinfo_md5"
        merge => { "[file][hash][md5]" => "[filescan][scan][hash][md5]" }
      }
    }

    if ([filescan][scan][hash][sha1]) {
      mutate {
        id => "mutate_merge_field_file_hash_fileinfo_sha1"
        merge => { "[file][hash][sha1]" => "[filescan][scan][hash][sha1]" }
      }
    }

    if ([filescan][scan][hash][sha256]) {
      mutate {
        id => "mutate_merge_field_file_hash_fileinfo_sha256"
        merge => { "[file][hash][sha256]" => "[filescan][scan][hash][sha256]" }
      }
    }

    if ([filescan][scan][hash][ssdeep]) {
      mutate {
        id => "mutate_merge_field_file_hash_fileinfo_ssdeep"
        merge => { "[file][hash][ssdeep]" => "[filescan][scan][hash][ssdeep]" }
      }
    }

    if ([filescan][scan][hash][tlsh]) {
      mutate {
        id => "mutate_merge_field_file_hash_fileinfo_tlsh"
        merge => { "[file][hash][tlsh]" => "[filescan][scan][hash][tlsh]" }
      }
    }

    # File/MIME types ###################################################################################################
    # ECS -> various -> file.mime_type
    # collect all file/MIME types under the parent [file][mime_type] array

    if ([filescan][file][flavors][mime]) {
      mutate {
        id => "mutate_merge_normalize_filescan_fileinfo_mime_type"
        merge => { "[file][mime_type]" => "[filescan][file][flavors][mime]" }
      }
    }

    # if ([filescan][scan][pe]) {
    #   # "mz_file" in [filescan][file][flavors][yara]
    #   # TODO: break file types into separate filters
    # }
    # if ([filescan][scan][elf]) {
    #   # "elf_file" in [filescan][file][flavors][yara]
    # }
    # if ([filescan][scan][macho]) {
    # }

    # if ([filescan][scan][clamav][signature]) {
    #     mutate {
    #       id => "add_clamav_hit_signature"
    #       copy => { "[filescan][scan][clamav][signature]" => "[rule][name]" }
    #       add_field => { "[event][module]" => "ClamAV" }
    #       add_field => { "[rule][category]" => "unknown" }
    #     }
    # }

    # mutate {
    #   remove_field => ["[filescan][scan][pe][resources]"]
    # }

    # from here a lot of this stuff mimics what is done for zeek's files.log, only from the record that came from the filescan metadata

    # move "up" some fields that are considered to be "multi-log" fields (eg., they # show up in many types of logs)
    mutate {
      id => "mutate_rename_filescan_zeek_common_fields"
      rename => { "[zeek][files][ts]"       => "[zeek][ts]" }
      rename => { "[zeek][files][uid]"      => "[zeek][uid]" }
      rename => { "[zeek][files][fuid]"     => "[zeek][fuid]" }
      rename => { "[zeek][files][is_orig]"  => "[network][is_orig]" }
      rename => { "[zeek][files][orig_h]"   => "[source][ip]" }
      rename => { "[zeek][files][orig_p]"   => "[source][port]" }
      rename => { "[zeek][files][resp_h]"   => "[destination][ip]" }
      rename => { "[zeek][files][resp_p]"   => "[destination][port]" }
    }

    # store parent_fuid with fuid
    if ([zeek][files][parent_fuid]) { mutate { id => "mutate_filescan_merge_normalize_zeek_files_parent_fuid"
                                                     merge => { "[zeek][fuid]" => "[zeek][files][parent_fuid]" } } }

    if ([zeek][uid]) {
      # set zeek connection UID as "rootId" (see logstash.conf output section)
      if (![rootId]) { mutate { id => "mutate_filescan_add_field_zeek_rootId"
                                add_field => { "[rootId]" => "%{[zeek][uid]}" } } }

      # ECS - zeek.uid -> event.id
      mutate { id => "mutate_filescan_add_field_ecs_id_uid"
               merge => { "[event][id]" => "[zeek][uid]" } }
    }

    if ([zeek][fuid]) {
      # ECS - zeek.uid -> event.id
      mutate { id => "mutate_filescan_add_field_ecs_id_fuid"
               merge => { "[event][id]" => "[zeek][fuid]" } }
    }

    # ECS -> zeek_files.(md5|sha1|sha256) -> file.hash.(md5|sha1|sha256)
    if ([zeek][files][md5])  { mutate { id => "mutate_filescan_add_field_ecs_files_hash_md5"
                                              add_field => { "[file][hash][md5]" => "%{[zeek][files][md5]}" } } }
    if ([zeek][files][sha1]) { mutate { id => "mutate_filescan_add_field_ecs_files_hash_sha1"
                                              add_field => { "[file][hash][sha1]" => "%{[zeek][files][sha1]}" } } }
    if ([file][sha256]) {
      mutate { id => "mutate_rename_filescan_file_sha256"
               rename => { "[file][sha256]" => "[file][hash][sha256]" } }
    } else if ([zeek][files][sha256]) {
      mutate { id => "mutate_filescan_add_field_ecs_files_hash_sha256"
               add_field => { "[file][hash][sha256]" => "%{[zeek][files][sha256]}" } }
    }

    if ([zeek][files][source]) {
      # do some normalization on files source
      mutate { id => "mutate_gsub_field_filescan_zeek_files_source_spicy_suffix"
               gsub => [ "[zeek][files][source]", "_(TCP|UDP|DATA)$", "" ] }
      mutate { id => "mutate_gsub_field_filescan_zeek_files_source_spicy_prefix"
               gsub => [ "[zeek][files][source]", "^SPICY_", "" ] }

      if ([zeek][files][source] =~ /^XOR decrypted from /) {
        # PE_XOR plugin writes source as "XOR decrypted from FM7Tr545kxt3ofR7x2-"..., let's
        # standardize that to just "XOR decrypted" and put the source fuid in parent_fuid
        grok {
          id => "grok_filescan_zeek_files_source_xor"
          match => { "[zeek][files][source]" => [ "decrypted%{SPACE}from%{SPACE}%{WORD:[@metadata][source_xor_fuid]}" ] }
        }
        if ([@metadata][source_xor_fuid]) { mutate { id => "mutate_merge_filescan_zeek_files_source_xor_parent_fuid"
                                                     merge => { "[zeek][files][parent_fuid]" => "[@metadata][source_xor_fuid]" } } }
        mutate { id => "mutate_replace_filescan_zeek_files_source_xor"
                 replace => { "[zeek][files][source]" => "XOR decrypted" } }

      } else if ([zeek][files][source] == "SSL") {
        # SSL->TLS to match up with what the service field has for cross-referencing
        mutate { id => "mutate_replace_filescan_zeek_files_source_ssl_to_tls"
                 replace => { "[zeek][files][source]" => "TLS" } }
      }

      # ECS -> various -> file.source
      mutate { id => "mutate_filescan_add_field_file_source"
               add_field => { "[file][source]" => "%{[zeek][files][source]}" } }

      # if we have a network protocol as a "source" field from the original zeek files.log, also store in protocols
      if (![network][protocol]) and
         ([zeek][files][source] !~ /^(<error|PNG|XOR|ZIP)/) {
        mutate { id => "mutate_filescan_merge_zeek_files_source_network_protocol"
                 merge => { "[network][protocol]" => "[zeek][files][source]" } }
        mutate { id => "mutate_filescan_lowercase_zeek_files_source_network_protocol"
                 lowercase => [ "[network][protocol]" ] }
        mutate { id => "mutate_filescan_merge_zeek_files_source_protocol"
                 merge => { "[protocol]" => "[network][protocol]" } }
      }
    }

    if ([file][path]) {
      mutate { id => "mutate_gsub_filescan_path"
               gsub => [ "[file][path]", "^/zeek/extracted-files/", "" ] }
      ruby {
        id => "ruby_filescan_zeek_files_extracted_uri_build"
        code => "
          uri = nil
          if (fName = event.get('[file][path]')) then
            if (tags = event.get('[tags]')) && tags.include?('_filebeat_zeek_hedgehog') then
              if (hName = event.get('[host][name]')) then
                uri = 'hh-extracted-files/' + hName + '/' + fName
              end
            else
              uri = 'extracted-files/' + fName
            end
          end
          event.set('[zeek][files][extracted_uri]', uri) unless uri.to_s.empty?
        "
      }
    }

  } else {
    drop { id => "drop_filescan_invalid_logs" }
  }

}
