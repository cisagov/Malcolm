filter {

  if ([event][provider] == "filescan") {

    if ([file][size]) {
      ruby {
        id => "ruby_filescan_file_size"
        code => "
          file_size = event.get('[file][size]').to_i
          event.set('[network][bytes]', file_size)
          event.set('[totDataBytes]', file_size)
        "
      }
    }

    # save the filescan's UUID id as into event.id
    mutate {
      id => "mutate_merge_event_id_filescan_id"
      merge => { "[event][id]" => "[id]" }
    }

    # ECS - "file" -> file.type
    mutate { id => "mutate_filescan_add_field_ecs_file_type"
             add_field => { "[file][type]" => "file" } }

    ruby {
        id => "ruby_filescan_results_processing"
        # TODO: remove the yara_rules thing once they're getting put into `rules` correctly,
        # pull them out from deeper in the meantime
        code => "
            scanners = Array(event.get('[results][strelka][result][scanners]') || []).compact
            scanners_to_rules = {}
            final_rules = []
            Array(event.get('[results][strelka][result][rules]') || []).each do |r|
              next unless r.is_a?(Hash) && r.key?('scanner') && r.key?('name')
              scanner = r['scanner']
              name = r['name']
              scanners |= [scanner]
              scanners_to_rules[scanner] ||= []
              scanners_to_rules[scanner] << name
              final_rules << name
            end
            yara_rules = Array(event.get('[results][strelka][result][scan][yara][matches]') || []).compact
            if yara_rules.any?
              scanners_to_rules['yara'] = yara_rules
              final_rules.concat(yara_rules)
            end
            final_rules.uniq!
            event.set('[filescan][hits]', scanners_to_rules) unless scanners_to_rules.empty?
            event.set('[event][module]', scanners) unless scanners.empty?
            event.set('[event][hits]', final_rules.length)
            if final_rules.length > 0
              event.set('[event][kind]', 'alert')
              event.set('[rule][name]', final_rules)
            else
              event.set('[event][kind]', 'event')
            end
        "
    }

    # TODO: do capa mapping:
#
#    if ('Capa' in [event][module]) {
#      # ECS - populate threat information for MITRE ATT&CK techniques specified by capa hits
#      ruby {
#          id => "ruby_signatures_attack_extract"
#          # matches array is like: 1) tactic name, 2) technique name, 3) sub-technique name, 4) technique number
#          # <MatchData
#          #  "Persistence::Create or Modify System Process::Windows Service [ATT&CK T1543.003]"
#          #    1:"Persistence"
#          #    2:"Create or Modify System Process"
#          #    3:"Windows Service"
#          #    4:"T1543.003">,
#          # <MatchData
#          #  "Execution::Shared Modules [ATT&CK T1129]"
#          #    1:"Execution"
#          #    2:"Shared Modules"
#          #    3:nil
#          #    4:"T1129">
#          init => "
#            require 'yaml'; $tacticIdMap = YAML.safe_load(File.read('/etc/mitre_attack_tactic_enterprise_ids.yaml'));
#          "
#          code => "
#            matches = Array.new
#            begin
#              Array(event.get('[rule][name]') || []).compact.each do |signature|
#                matches.push(/(.+?)::(.+?)(?:::(.+?))?\s*\[ATT&CK\s*(.+?)\]/.match(signature))
#              end
#            rescue Exception => e
#              event.set('ruby_exception', 'ruby_signatures_attack_extract: ' + e.message)
#            end
#            if ! matches.empty? then
#                tacticNames = matches.map{ |x| x[1].gsub(' ', '_') }.reject{ |e| e.nil? || e&.empty? }
#                tacticIds = tacticNames.clone.map(&:clone).map{ |x| $tacticIdMap[x] }.reject{ |e| e.nil? || e&.empty? }
#                tacticRefs = tacticIds.clone.map(&:clone).map { |x| x.gsub(/\..*/, '').prepend('https://attack.mitre.org/tactics/') }.uniq.reject{ |e| e.nil? || e&.empty? }
#                techniqueNames = matches.map{ |x| [x[2], x[3]].reject{ |e| e.nil? || e&.empty? }.join(':') }.reject{ |e| e.nil? || e&.empty? }
#                techniqueIds = matches.map{ |x| x[4] }.reject{ |e| e.nil? || e&.empty? }
#                techniqueRefs = techniqueIds.clone.map(&:clone).map { |x| x.gsub(/\..*/, '').prepend('https://attack.mitre.org/techniques/') }.uniq.reject{ |e| e.nil? || e&.empty? }
#                event.set('[threat][tactic][name]', tacticNames.uniq) unless tacticNames.to_a.empty?
#                event.set('[threat][tactic][id]', tacticIds.uniq) unless tacticIds.to_a.empty?
#                event.set('[threat][tactic][reference]', tacticRefs.uniq) unless tacticRefs.to_a.empty?
#                event.set('[threat][technique][name]', techniqueNames.uniq) unless techniqueNames.to_a.empty?
#                event.set('[threat][technique][id]', techniqueIds.uniq) unless techniqueIds.to_a.empty?
#                event.set('[threat][technique][reference]', techniqueRefs.uniq) unless techniqueRefs.to_a.empty?
#                event.set('[threat][framework]', 'MITRE ATT&CK')
#            end
#          "
#      }
#    } # Capa
#
#    # get more specific than 'Signatures::Sensitive_Signature' if we can
#    if ([rule][category]) and ([rule][category][0] == 'Signatures::Sensitive_Signature') {
#      if ([threat][tactic][name]) {
#        mutate { id => "mutate_merge_zeek_sensitive_signature_tactic"
#                 merge => { "[@metadata][zeek_sensitive_signature_replacement]" => "[threat][tactic][name]" } }
#      } else if ([threat][technique][name]) {
#        mutate { id => "mutate_merge_zeek_sensitive_signature_technique"
#                 merge => { "[@metadata][zeek_sensitive_signature_replacement]" => "[threat][technique][name]" } }
#      } else if ([threat][framework]) {
#        mutate { id => "mutate_merge_zeek_sensitive_signature_framework"
#                 merge => { "[@metadata][zeek_sensitive_signature_replacement]" => "[threat][framework]" } }
#      }
#      if ([@metadata][zeek_sensitive_signature_replacement]) {
#        mutate { id => "remove_field_zeek_sensitive_signature"
#                 remove_field => [ "[rule][category][0]" ] }
#        mutate { id => "mutate_merge_zeek_sensitive_signature_replacement"
#                 merge => { "[rule][category]" => "[@metadata][zeek_sensitive_signature_replacement]" } }
#      } else if ([event][hits]) and ([event][hits] > 1) {
#        mutate { id => "remove_field_zeek_sensitive_signature_multiple"
#                 remove_field => [ "[rule][category][0]" ] }
#        ruby { id => "ruby_add_field_zeek_multiple_signatures"
#               code => "event.set('[rule][category]', [ 'Signatures::Multiple_Signatures', event.get('[rule][category]') ].flatten.reject{ |e| e.nil? || e&.empty? })" }
#      }
#    }
#
    mutate {
      id => "mutate_add_field_env_logstash_severity_scoring_filescan"
      add_field => { "[@metadata][ENV_LOGSTASH_SEVERITY_SCORING_FILESCAN]" => "${LOGSTASH_SEVERITY_SCORING:false}" }
    }
    if ([@metadata][ENV_LOGSTASH_SEVERITY_SCORING_FILESCAN] == "true") {
      # assign score to signatures based on engine
      if ([filescan][hits][clamav]) {
        mutate { id => "mutate_add_field_severity_filescan_clamav"
                 add_field => { "[event][severity_tags]" => "Signature (ClamAV)" } }
      } else if ([filescan][hits][yara]) {
        mutate { id => "mutate_add_field_severity_filescan_yara"
                 add_field => { "[event][severity_tags]" => "Signature (YARA)" } }
      } else if ([filescan][hits][capa]) {
        mutate { id => "mutate_add_field_severity_filescan_capa"
                 add_field => { "[event][severity_tags]" => "Signature (capa)" } }
      } else if ([rule][name]) {
        mutate { id => "mutate_add_field_severity_filescan_other"
                 add_field => { "[event][severity_tags]" => "Signature" } }
      }
    }

    # generic adds
    # https://www.elastic.co/guide/en/ecs/current/ecs-file.html

    if ([results][strelka][result][scan][entropy][entropy]) {
      mutate {
        id => "mutate_filescan_add_entropy"
        add_field =>  { "[file][entropy]" => "%{[results][strelka][result][scan][entropy][entropy]}" }
      }
    }

    if ([filescan][file][name]) {
      mutate {
        id => "mutate_merge_normalize_filescan_filename"
        merge => { "[file][path]" => "[filescan][file][name]" }
      }
    }

    # hashes (will be merged into "related" in 98_finalize.conf)
    # https://www.elastic.co/guide/en/ecs/current/ecs-hash.html
    # https://www.elastic.co/guide/en/ecs/current/ecs-related.html

    if ([filescan][scan][hash][md5]) {
      mutate {
        id => "mutate_merge_field_file_hash_fileinfo_md5"
        merge => { "[file][hash][md5]" => "[filescan][scan][hash][md5]" }
      }
    }

    if ([filescan][scan][hash][sha1]) {
      mutate {
        id => "mutate_merge_field_file_hash_fileinfo_sha1"
        merge => { "[file][hash][sha1]" => "[filescan][scan][hash][sha1]" }
      }
    }

    if ([filescan][scan][hash][sha256]) {
      mutate {
        id => "mutate_merge_field_file_hash_fileinfo_sha256"
        merge => { "[file][hash][sha256]" => "[filescan][scan][hash][sha256]" }
      }
    }

    if ([filescan][scan][hash][ssdeep]) {
      mutate {
        id => "mutate_merge_field_file_hash_fileinfo_ssdeep"
        merge => { "[file][hash][ssdeep]" => "[filescan][scan][hash][ssdeep]" }
      }
    }

    if ([filescan][scan][hash][tlsh]) {
      mutate {
        id => "mutate_merge_field_file_hash_fileinfo_tlsh"
        merge => { "[file][hash][tlsh]" => "[filescan][scan][hash][tlsh]" }
      }
    }

    # File/MIME types ###################################################################################################
    # ECS -> various -> file.mime_type
    # collect all file/MIME types under the parent [file][mime_type] array

    if ([filescan][file][flavors][mime]) {
      mutate {
        id => "mutate_merge_normalize_filescan_fileinfo_mime_type"
        merge => { "[file][mime_type]" => "[filescan][file][flavors][mime]" }
      }
    }
    if ([results][strelka][result][file][mime_type]) {
      mutate {
        id => "mutate_merge_normalize_filescan_result_file_mime_type"
        merge => { "[file][mime_type]" => "[results][strelka][result][file][mime_type]" }
      }
    }
    if ([results][strelka][result][scan][exiftool][mime_type]) {
      mutate {
        id => "mutate_merge_normalize_filescan_result_scan_exiftool_mime_type"
        merge => { "[file][mime_type]" => "[results][strelka][result][scan][exiftool][mime_type]" }
      }
    }

    # from here a lot of this stuff mimics what is done for zeek's files.log, only from the record that came from the filescan metadata

    if [@metadata][log_file_type] {
      # move "up" some fields that are considered to be "multi-log" fields (eg., they show up in many types of logs)
      mutate {
        id => "mutate_rename_filescan_zeek_common_fields"
        rename => { "[zeek][%{[@metadata][log_file_type]}][ts]"         => "[zeek][ts]" }
        rename => { "[zeek][%{[@metadata][log_file_type]}][uid]"        => "[zeek][uid]" }
        rename => { "[zeek][%{[@metadata][log_file_type]}][fuid]"       => "[zeek][fuid]" }
        rename => { "[zeek][%{[@metadata][log_file_type]}][is_orig]"    => "[network][is_orig]" }
        # this seems redundant but depending on how it came here it might look like any one of these
        rename => { "[zeek][%{[@metadata][log_file_type]}][id][orig_h]" => "[source][ip]" }
        rename => { "[zeek][%{[@metadata][log_file_type]}][id][orig_p]" => "[source][port]" }
        rename => { "[zeek][%{[@metadata][log_file_type]}][id][resp_h]" => "[destination][ip]" }
        rename => { "[zeek][%{[@metadata][log_file_type]}][id][resp_p]" => "[destination][port]" }
        rename => { "[zeek][%{[@metadata][log_file_type]}][id.orig_h]"  => "[source][ip]" }
        rename => { "[zeek][%{[@metadata][log_file_type]}][id.orig_p]"  => "[source][port]" }
        rename => { "[zeek][%{[@metadata][log_file_type]}][id.resp_h]"  => "[destination][ip]" }
        rename => { "[zeek][%{[@metadata][log_file_type]}][id.resp_p]"  => "[destination][port]" }
        rename => { "[zeek][%{[@metadata][log_file_type]}][orig_h]"     => "[source][ip]" }
        rename => { "[zeek][%{[@metadata][log_file_type]}][orig_p]"     => "[source][port]" }
        rename => { "[zeek][%{[@metadata][log_file_type]}][resp_h]"     => "[destination][ip]" }
        rename => { "[zeek][%{[@metadata][log_file_type]}][resp_p]"     => "[destination][port]" }
      }
    }

    # store parent_fuid with fuid
    if ([zeek][files][parent_fuid]) {
      mutate { id => "mutate_filescan_merge_normalize_zeek_files_parent_fuid"
               merge => { "[zeek][fuid]" => "[zeek][files][parent_fuid]" } }
    }

    if ([zeek][uid]) {
      # set zeek connection UID as "rootId" (see logstash.conf output section)
      if (![rootId]) { mutate { id => "mutate_filescan_copy_zeek_rootId"
                                copy => { "[zeek][uid]" => "[rootId]" } } }

      # ECS - zeek.uid -> event.id
      mutate { id => "mutate_filescan_merge_ecs_id_uid"
               merge => { "[event][id]" => "[zeek][uid]" } }
    }

    if ([zeek][fuid]) {
      # ECS - zeek.uid -> event.id
      mutate { id => "mutate_filescan_merge_ecs_id_fuid"
               merge => { "[event][id]" => "[zeek][fuid]" } }
    }

    # ECS -> zeek_files.(md5|sha1|sha256) -> file.hash.(md5|sha1|sha256)
    if ([zeek][files][md5])  { mutate { id => "mutate_filescan_copy_ecs_files_hash_md5"
                                              copy => { "[zeek][files][md5]" => "[file][hash][md5]" } } }
    if ([zeek][files][sha1]) { mutate { id => "mutate_filescan_copy_ecs_files_hash_sha1"
                                              copy => { "[zeek][files][sha1]" => "[file][hash][sha1]" } } }
    if ([file][sha256]) {
      mutate { id => "mutate_rename_filescan_file_sha256"
               rename => { "[file][sha256]" => "[file][hash][sha256]" } }
    } else if ([zeek][files][sha256]) {
      mutate { id => "mutate_filescan_copy_ecs_files_hash_sha256"
               copy => { "[zeek][files][sha256]" => "[file][hash][sha256]" } }
    }

    if ([zeek][files][source]) {
      # do some normalization on files source
      mutate { id => "mutate_gsub_field_filescan_zeek_files_source_spicy_suffix"
               gsub => [ "[zeek][files][source]", "_(TCP|UDP|DATA)$", "" ] }
      mutate { id => "mutate_gsub_field_filescan_zeek_files_source_spicy_prefix"
               gsub => [ "[zeek][files][source]", "^SPICY_", "" ] }

      if ([zeek][files][source] =~ /^XOR decrypted from /) {
        # PE_XOR plugin writes source as "XOR decrypted from FM7Tr545kxt3ofR7x2-"..., let's
        # standardize that to just "XOR decrypted" and put the source fuid in parent_fuid
        grok {
          id => "grok_filescan_zeek_files_source_xor"
          match => { "[zeek][files][source]" => [ "decrypted%{SPACE}from%{SPACE}%{WORD:[@metadata][source_xor_fuid]}" ] }
        }
        if ([@metadata][source_xor_fuid]) { mutate { id => "mutate_merge_filescan_zeek_files_source_xor_parent_fuid"
                                                     merge => { "[zeek][files][parent_fuid]" => "[@metadata][source_xor_fuid]" } } }
        mutate { id => "mutate_replace_filescan_zeek_files_source_xor"
                 replace => { "[zeek][files][source]" => "XOR decrypted" } }

      } else if ([zeek][files][source] == "SSL") {
        # SSL->TLS to match up with what the service field has for cross-referencing
        mutate { id => "mutate_replace_filescan_zeek_files_source_ssl_to_tls"
                 replace => { "[zeek][files][source]" => "TLS" } }
      }

      # ECS -> various -> file.source
      mutate { id => "mutate_filescan_rename_file_source"
               rename => { "[zeek][files][source]" => "[file][source]" } }

      if ([zeek][files][mime_type]) {
        mutate {
          id => "mutate_merge_normalize_filescan_zeek_files_mime_type"
          merge => { "[file][mime_type]" => "[zeek][files][mime_type]" }
        }
      }

      # if we have a network protocol as a "source" field from the original zeek files.log, also store in protocols
      if (![network][protocol]) and
         ([zeek][files][source]) and
         ([zeek][files][source] !~ /^(<error|PNG|XOR|ZIP)/) {
        mutate { id => "mutate_filescan_merge_zeek_files_source_network_protocol"
                 merge => { "[network][protocol]" => "[zeek][files][source]" } }
        mutate { id => "mutate_filescan_lowercase_zeek_files_source_network_protocol"
                 lowercase => [ "[network][protocol]" ] }
        mutate { id => "mutate_filescan_merge_zeek_files_source_protocol"
                 merge => { "[protocol]" => "[network][protocol]" } }
      }
    }

    if ([file][path]) {
      mutate { id => "mutate_gsub_filescan_path"
               gsub => [ "[file][path]", "^/zeek/extract_files/", "" ] }
      ruby {
        id => "ruby_filescan_zeek_files_extracted_uri_build"
        # don't store extracted_uri if the file probably wasn't preserved
        init => "@preservation = ENV['FILESCAN_PRESERVATION'] || 'all'"
        code => "
          if ((@preservation == 'all') ||
              ((@preservation == 'quarantined') && (event.get('[event][hits]').to_i > 0))) &&
             (fName = event.get('[file][path]')) then
            uri = nil
            if (tags = event.get('[tags]')) && tags.include?('_filebeat_zeek_hedgehog') then
              if (hName = event.get('[host][name]')) then
                uri = 'hh-extracted-files/' + hName + '/' + fName
              end
            else
              uri = 'extracted-files/' + fName
            end
            event.set('[zeek][files][extracted_uri]', uri) unless uri.to_s.empty?
          end
        "
        remove_field => [ "[zeek][files][extracted]" ]
      }
    }
  }

}
